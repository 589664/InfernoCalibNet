{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from dotenv import load_dotenv\n",
    "from src.XRayDataset import XRayDataset\n",
    "from src.utils import compute_mean_std, compute_class_weights\n",
    "from src.prePro import preprocess_metadata, calculate_balanced_label_statistics, distribution_df_split\n",
    "from src.ICNTrainer import ICNTrainer\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "data_dir = os.getenv('DATA_DIR')\n",
    "\n",
    "filtered_df = preprocess_metadata(\n",
    "    f'../{data_dir}/raw/xraysMD.csv',\n",
    "    f'../{data_dir}/raw/xrays',\n",
    "    f'../{data_dir}/processed/xraysMD.csv'\n",
    ")\n",
    "\n",
    "filtered_df_stats = calculate_balanced_label_statistics(filtered_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 7000\n",
      "Test/Validation set size: 3000\n",
      "\n",
      "Combined label distribution statistics:\n",
      "                    Training  Test/Validation\n",
      "Atelectasis              687              268\n",
      "Cardiomegaly             211               78\n",
      "Consolidation            229               98\n",
      "Edema                     99               39\n",
      "Effusion                 654              292\n",
      "Emphysema                149               61\n",
      "Fibrosis                 135               49\n",
      "Hernia                    26                4\n",
      "Infiltration            1030              434\n",
      "Mass                     270              122\n",
      "No Finding              4037             1757\n",
      "Nodule                   338              166\n",
      "Pleural_Thickening       230               94\n",
      "Pneumonia                 79               28\n",
      "Pneumothorax             293              135\n",
      "Total                   8467             3625\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = distribution_df_split(filtered_df, train_size=7000, test_size=3000)\n",
    "\n",
    "# Print sizes of the resulting DataFrames\n",
    "print(f\"Training set size: {len(train_df)}\")\n",
    "print(f\"Test/Validation set size: {len(test_df)}\")\n",
    "\n",
    "# Calculate the label distribution for the training and test sets\n",
    "train_distribution = pd.Series([label for labels in train_df['Labels'] for label in labels]).value_counts()\n",
    "test_distribution = pd.Series([label for labels in test_df['Labels'] for label in labels]).value_counts()\n",
    "\n",
    "# Combine both distributions into a DataFrame\n",
    "statistics_df = pd.DataFrame({\n",
    "    'Training': train_distribution,\n",
    "    'Test/Validation': test_distribution\n",
    "})\n",
    "\n",
    "# Fill NaN values with 0 (in case a label is not present in either set)\n",
    "statistics_df.fillna(0, inplace=True)\n",
    "\n",
    "# Add a total row to both columns\n",
    "statistics_df.loc['Total'] = statistics_df.sum()\n",
    "\n",
    "print(\"\\nCombined label distribution statistics:\")\n",
    "print(statistics_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m image_paths \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/raw/xrays/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m image_id \u001b[38;5;129;01min\u001b[39;00m train_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mImageID\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m      3\u001b[0m img_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m  \u001b[38;5;66;03m# Set to your desired size\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m mean, std \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_mean_std\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_paths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComputed Mean: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmean\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Computed Std: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstd\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\Desktop\\master\\InfernoCalibNet\\src\\utils.py:37\u001b[0m, in \u001b[0;36mcompute_mean_std\u001b[1;34m(image_paths, img_size)\u001b[0m\n\u001b[0;32m     34\u001b[0m variance_sum \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m img_path \u001b[38;5;129;01min\u001b[39;00m image_paths:\n\u001b[1;32m---> 37\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mload_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m     img_np \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(img)\u001b[38;5;241m.\u001b[39mflatten()  \u001b[38;5;66;03m# Convert image to a numpy array and flatten it\u001b[39;00m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;66;03m# Incrementally update the mean and variance\u001b[39;00m\n",
      "File \u001b[1;32m~\\Desktop\\master\\InfernoCalibNet\\src\\utils.py:20\u001b[0m, in \u001b[0;36mload_image\u001b[1;34m(image_path, img_size)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;124;03mLoads an image from the specified path, converts it to grayscale, and resizes it to the specified square size.\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03m    Image.Image: The processed grayscale and resized image.\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     19\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(image_path)\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Convert to grayscale\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m img_resized \u001b[38;5;241m=\u001b[39m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Resize to square of size img_size\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m img_resized\n",
      "File \u001b[1;32mc:\\Users\\maksi\\Desktop\\master\\InfernoCalibNet\\.venv\\Lib\\site-packages\\PIL\\Image.py:2365\u001b[0m, in \u001b[0;36mImage.resize\u001b[1;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[0;32m   2353\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   2354\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreduce(factor, box\u001b[38;5;241m=\u001b[39mreduce_box)\n\u001b[0;32m   2355\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreduce)\n\u001b[0;32m   2356\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m Image\u001b[38;5;241m.\u001b[39mreduce(\u001b[38;5;28mself\u001b[39m, factor, box\u001b[38;5;241m=\u001b[39mreduce_box)\n\u001b[0;32m   2357\u001b[0m         )\n\u001b[0;32m   2358\u001b[0m         box \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   2359\u001b[0m             (box[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_x,\n\u001b[0;32m   2360\u001b[0m             (box[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_y,\n\u001b[0;32m   2361\u001b[0m             (box[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_x,\n\u001b[0;32m   2362\u001b[0m             (box[\u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_y,\n\u001b[0;32m   2363\u001b[0m         )\n\u001b[1;32m-> 2365\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbox\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Compute mean and std using a list of image paths\n",
    "image_paths = [f\"../data/raw/xrays/{image_id}.png\" for image_id in train_df['ImageID']]\n",
    "img_size = 1000  # Set to your desired size\n",
    "\n",
    "mean, std = compute_mean_std(image_paths, img_size)\n",
    "\n",
    "print(f\"Computed Mean: {mean}, Computed Std: {std}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images batch shape: torch.Size([20, 1, 300, 300])\n",
      "Labels batch shape: torch.Size([20, 15])\n",
      "First image shape: torch.Size([1, 300, 300])\n",
      "First label: tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "# Testing the DataLoader\n",
    "data_iter = iter(train_loader)\n",
    "images, labels = next(data_iter)\n",
    "\n",
    "# Print the shapes of the batch\n",
    "print(f\"Images batch shape: {images.shape}\")  # Should be [batch_size, channels, height, width]\n",
    "print(f\"Labels batch shape: {labels.shape}\")  # Should be [batch_size, num_labels]\n",
    "\n",
    "# Check the individual data points (optional)\n",
    "print(f\"First image shape: {images[0].shape}\")\n",
    "print(f\"First label: {labels[0]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
